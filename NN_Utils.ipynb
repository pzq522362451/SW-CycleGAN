{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NN_Utils.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPHD4quXWDM+Dm1wPMRJGBa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# SEM"],"metadata":{"id":"LKHtqwQyRcet"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ociyo_DTRUwc"},"outputs":[],"source":["#SEM\n","from tensorflow.keras.layers import GlobalAveragePooling1D, Reshape, Dense, Input\n","from keras import backend as K\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply, add, Permute, Conv2D\n","\n","def SqueezeAndExcitation(inputs, ratio=8):\n","    b,_,_, c = inputs.shape\n","\n","    x = GlobalAveragePooling2D()(inputs)\n","    x = Dense(c//ratio, activation=\"relu\",kernel_initializer='he_normal', use_bias=False)(x)\n","    x = Dense(c, activation=\"sigmoid\", kernel_initializer='he_normal',use_bias=False)(x)\n","\n","    x = multiply([inputs, x])\n","    return x"]},{"cell_type":"markdown","source":["# CNN"],"metadata":{"id":"t67cXA7BRgh6"}},{"cell_type":"code","source":["\n","from tensorflow.keras.layers import Conv2D, Dropout, Flatten, Dense, Reshape, Conv2DTranspose, ReLU, BatchNormalization, LeakyReLU,Input,GaussianNoise,Dense,Add\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import concatenate,Embedding\n","from tensorflow import keras\n","from tensorflow.keras.initializers import RandomNormal\n","\n","def add_label(label,shape1,shape2,shape3,depth):\n","    label_emb = Embedding(depth, 32)(label)\n","    one_hot_label = Reshape((shape1, shape2, shape3))(Dense(shape1 * shape2 * shape3, activation=keras.activations.relu)(label_emb))\n","    return one_hot_label\n","  \n","def do_norm(norm):\n","    if norm == \"batch\":\n","        _norm = BatchNormalization()\n","    elif norm == \"instance\":\n","        _norm = InstanceNormalization()\n","    else:\n","        _norm = []\n","    return _norm\n","\n","def gen_block_down(filters,k_size,strides,padding,input,norm=\"instance\"):\n","\n","    g = Conv2D(filters, k_size, strides=strides, padding=padding)(input)\n","    g = do_norm(norm)(g)\n","    g = LeakyReLU()(g)\n","    return g\n","\n","def gen_block_up(filters,k_size,strides,padding,input,norm=\"instance\"):\n","\n","    g = Conv2DTranspose(filters, k_size, strides=strides, padding=padding)(input)\n","    g = do_norm(norm)(g)\n","    g = ReLU()(g)\n","    return g"],"metadata":{"id":"GVb-LvrkRgym"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ResNet"],"metadata":{"id":"0sexsYySSRGH"}},{"cell_type":"code","source":["def resnet_block(n_filters, input_layer):\n","\n","    # weight initialization\n","    init = RandomNormal()\n","\n","    # first layer convolutional layer\n","    g = Conv2D(n_filters, 5, padding='same', kernel_initializer=init)(input_layer)\n","    g = InstanceNormalization(axis=-1)(g)\n","    g = ReLU()(g)\n","\n","    # second convolutional layer\n","    g = Conv2D(n_filters, 5, padding='same', kernel_initializer=init)(g)\n","    g = InstanceNormalization(axis=-1)(g)\n","\n","    # concatenate merge channel-wise with input layer\n","    g = Add()([g, input_layer])\n","    # g = ReLU()(g)\n","    return g"],"metadata":{"id":"Y5Vrq_oPSfMO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ResNet with SEM"],"metadata":{"id":"e8ovtCIqSWep"}},{"cell_type":"code","source":["def resnet_block_SENet(n_filters, input_layer):\n","\n","  # weight initialization\n","  init = RandomNormal(stddev=0.02)\n","\n","  #residual\n","  # first layer convolutional layer\n","  g = Conv2D(n_filters, 5, padding='same', kernel_initializer=init)(input_layer)\n","  g = InstanceNormalization(axis=-1)(g)\n","  g = ReLU()(g)\n","\n","  # second convolutional layer\n","  g = Conv2D(n_filters, 5, padding='same', kernel_initializer=init)(g)\n","  g = InstanceNormalization(axis=-1)(g)\n","  \n","  # sem\n","  x_se=SqueezeAndExcitation(g)\n","  x_se = InstanceNormalization(axis=-1)(x_se)\n","\n","  # concatenate merge channel-wise with input layer\n","  g = Add()([x_se, input_layer])\n","\n","  return g"],"metadata":{"id":"4x-aVXs1ScE0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Uncondtional Discriminator"],"metadata":{"id":"cbB3NqRfRvBn"}},{"cell_type":"code","source":["def mnist_uni_disc_cnn(input_shape, use_bn=True,name='discriminator'):\n","\n","    in_image=Input(shape=input_shape)\n","    g = GaussianNoise(0.01)(in_image)\n","    # [n, 28, 28, n] -> [n, 14, 14, 64]\n","    g=Conv2D(64, (4, 4), strides=(2, 2), padding='same', input_shape=input_shape)(g)\n","    if use_bn:\n","        BatchNormalization()(g)\n","    g=LeakyReLU()(g)\n","    g=Dropout(0.3)(g)\n","    # -> [n, 7, 7, 128]\n","    g=Conv2D(128, (4, 4), strides=(2, 2), padding='same')(g)\n","    if use_bn:\n","        BatchNormalization()(g)\n","    g=LeakyReLU()(g)\n","    g=Dropout(0.3)(g)\n","    g=Flatten()(g)\n","    out=Dense(1)(g)\n","\n","    model = Model(in_image, out, name=name)\n","    # model.summary()\n","\n","    return model"],"metadata":{"id":"jUE-_MNPR_T3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Unconditional Generator"],"metadata":{"id":"eIU-n9wCRzh5"}},{"cell_type":"code","source":["def mnist_uni_img2img(img_shape, name=\"generator\"):\n","    in_image = Input(shape=(28, 28, 1))\n","    # [n, 28, 28, n] -> [n, 14, 14, 64]\n","    g = gen_block_down(64, (4, 4), (2, 2), \"same\", in_image)\n","    # -> [n, 7, 7, 128]\n","    g = gen_block_down(128, (4, 4), (2, 2), \"same\", g)\n","    # -> [n, 14, 14, 64]\n","    g = gen_block_up(64, (4, 4), (2, 2), \"same\", g)\n","    # -> [n, 28, 28, 32]\n","    g = gen_block_up(32, (4, 4), (2, 2), \"same\", g)\n","    # -> [n, 28, 28, 1]\n","    out_image = Conv2D(img_shape[-1], (4, 4), strides=(1, 1),\n","                       padding='same', activation=keras.activations.tanh)(g)\n","\n","    model=Model(in_image,out_image,name=name)\n","    # model.summary()\n","    return model"],"metadata":{"id":"5GLc0r12R_xw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Conditional Discriminator"],"metadata":{"id":"4pOelMHnR3qn"}},{"cell_type":"code","source":["def condition_mnist_uni_disc_cnn(input_shape, use_bn=True,name='discriminator'):\n","\n","    in_image=Input(shape=input_shape)#(28,28,1)\n","    g = GaussianNoise(0.01)(in_image)#(28,28,1)\n","\n","    label = Input(shape=(), dtype=tf.int32)#<----input\n","    image_one_hot_labels=add_label(label,shape1=28,shape2=28,shape3=1,depth=10)\n","    u = tf.concat((in_image, image_one_hot_labels), axis=3)\n","\n","    # [n, 28, 28, n] -> [n, 14, 14, 64]\n","    g=Conv2D(64, (4, 4), strides=(2, 2), padding='same', input_shape=input_shape)(u)\n","    if use_bn:\n","        BatchNormalization()(g)\n","    g=LeakyReLU()(g)\n","    g=Dropout(0.3)(g)\n","    # -> [n, 7, 7, 128]\n","    g=Conv2D(128, (4, 4), strides=(2, 2), padding='same')(g)\n","    if use_bn:\n","        BatchNormalization()(g)\n","    g=LeakyReLU()(g)\n","    g=Dropout(0.3)(g)\n","    g=Flatten()(g)\n","    out=Dense(1)(g)\n","\n","    model = Model([in_image,label], out, name=name)\n","    # model.summary()\n","\n","    return model"],"metadata":{"id":"tYGW7DwLSAjV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Conditional Generator (With ResNet)"],"metadata":{"id":"mBV0BjpYR7Wg"}},{"cell_type":"code","source":["def condition_mnist_uni_img2img(img_shape, name=\"generator\"):\n","    in_image = Input(shape=img_shape)#<----input\n","\n","    label = Input(shape=(), dtype=tf.int32)#<----input\n","\n","    label_onehot=add_label(label,28,28,1,10)\n","    u = tf.concat((in_image, label_onehot), axis=3)\n","\n","    # [n, 28, 28, n] -> [n, 14, 14, 64]\n","    enc = gen_block_down(64, (4, 4), (2, 2), \"same\", u)\n","    # -> [n, 7, 7, 128]\n","    enc = gen_block_down(128, (4, 4), (2, 2), \"same\", enc)\n","\n","    enc=resnet_block(128,enc)\n","    enc=resnet_block(128,enc)\n","\n","    ####################################\n","\n","    # -> [n, 14, 14, 64]\n","    \n","    dec = gen_block_up(64, (4, 4), (2, 2), \"same\", enc)\n","    # -> [n, 28, 28, 32]\n","    dec = gen_block_up(32, (4, 4), (2, 2), \"same\", dec)\n","\n","    # -> [n, 28, 28, 1]\n","    out_image = Conv2D(img_shape[-1], (4, 4), strides=(1, 1),\n","                       padding='same', activation=keras.activations.tanh)(dec)\n","\n","    model=Model([in_image,label],out_image,name=name)\n","    # model.summary()\n","    return model"],"metadata":{"id":"MdzJVpkQSBE1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Conditional Generator (With ResNet-SEM)"],"metadata":{"id":"DG46syFaSvHi"}},{"cell_type":"code","source":["def condition_mnist_uni_img2img_sem(img_shape, name=\"generator\"):\n","    in_image = Input(shape=img_shape)#<----input\n","\n","    label = Input(shape=(), dtype=tf.int32)#<----input\n","\n","    label_onehot=add_label(label,28,28,1,10)\n","    u = tf.concat((in_image, label_onehot), axis=3)\n","\n","    # [n, 28, 28, n] -> [n, 14, 14, 64]\n","    enc = gen_block_down(64, (4, 4), (2, 2), \"same\", u)\n","    # -> [n, 7, 7, 128]\n","    enc = gen_block_down(128, (4, 4), (2, 2), \"same\", enc)\n","\n","    enc=resnet_block_SENet(128,enc)\n","    enc=resnet_block_SENet(128,enc)\n","\n","    ####################################\n","\n","    # -> [n, 14, 14, 64]\n","    \n","    dec = gen_block_up(64, (4, 4), (2, 2), \"same\", enc)\n","    # -> [n, 28, 28, 32]\n","    dec = gen_block_up(32, (4, 4), (2, 2), \"same\", dec)\n","\n","    # -> [n, 28, 28, 1]\n","    out_image = Conv2D(img_shape[-1], (4, 4), strides=(1, 1),\n","                       padding='same', activation=keras.activations.tanh)(dec)\n","\n","    model=Model([in_image,label],out_image,name=name)\n","    # model.summary()\n","    return model"],"metadata":{"id":"HOrH4TJbSvRb"},"execution_count":null,"outputs":[]}]}